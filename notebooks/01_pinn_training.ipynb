{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a829885c-8023-40b8-8a36-31a91c4c4262",
   "metadata": {
    "id": "a829885c-8023-40b8-8a36-31a91c4c4262"
   },
   "source": [
    "# PhotonOrbitSolver Training\n",
    "> African Institute of Mathematical Sciences (AIMS), Cape Town, South Africa<br>\n",
    "> Created: March 2025 Claire David, Tlotlo M. Oepeng, Harrison B. Prosper\n",
    "\n",
    "## Introduction\n",
    "This notebook trains a Physics-Informed Neural Network (PINN) [1, 2] to solve the following nonlinear ordinary differential equation (ODE):\n",
    "\n",
    "\\begin{align}\n",
    "  \\overset{\\textstyle\\cdot\\cdot}{u}  \\: + \\: u - \\: 3 \\: \\frac{u^2}{2}  & = \\: 0,\n",
    "\\end{align}\n",
    "\n",
    "This equation describes the orbit of photons in a Schwarzschild spacetime about a spherically symmetric body of mass $M$.\n",
    "\n",
    "### Notation\n",
    "Our variable of interest here is\n",
    "\n",
    "\\begin{align}\n",
    "  u & = \\: \\frac{r_s }{ r},\n",
    "\\end{align}\n",
    "\n",
    "where $r_s$ is the Schwarzschild radius is defined as $r_s = \\: \\frac{2 G M}{c^2},$ where $G$ is Newton's gravitational constant and $c$ is the speed of light in vacuum.\n",
    "\n",
    "\n",
    "If $C$ is the proper circumference of a circle centered at the center of mass,\n",
    "in a Schwarzschild spacetime, the radial coordinate $r \\equiv \\frac{C}{2\\pi}$ differs from the proper radial distance.\n",
    "\n",
    "\n",
    "The overdot here ($\\overset{\\textstyle\\cdot\\cdot}{u}$) indicates differentiation with respect to $\\phi$, the azimuthal angle in a spherical polar coordinate system, $(r, \\theta, \\phi)$. Here $\\theta$ is set to $\\pi \\, / \\, 2$ without loss of generality.\n",
    "\n",
    "\n",
    "The initial conditions are\n",
    "\\begin{align}\n",
    "u\\,(0) &= u_0 \\\\\n",
    "\\overset{\\textstyle\\cdot}{u}\\,(0) &= v_0.\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "### Approach\n",
    "The ODE is solved using a PINN following the approach in [3]. The neural network is described by the function $g_\\beta(\\phi; u_0, v_0),$ where $\\beta$ are the network's trainable weights.  \n",
    "  \n",
    "We use the following Ansatz from the theory of connections (ToC) [4] that incorporates the initial conditions explicitly:\n",
    "\n",
    "\\begin{align}\n",
    "    u(\\phi; u_0, v_0)  &= u_0 + g_\\beta(\\phi; u_0, v_0) - g_\\beta(0; u_0, v_0) + \\phi \\left[ v_0 - \\dot{g}_\\beta(0; u_0, v_0) \\right], \\\\[1ex]\n",
    "    \\dot{u}(\\phi; u_0, v_0) &= v_0 + \\dot{g}_\\beta(\\phi; u_0, v_0) - \\dot{g}_\\beta(0; u_0, v_0),\n",
    "\\end{align}\n",
    "\n",
    "### References\n",
    "[1] B. Moseley, [Deep Learning in Scientific Computing (2023)](https://camlab.ethz.ch/teaching/deep-learning-in-scientific-computing-2023.html), ETH ZÃ¼rich, Computational and Applied Mathematics Laboratory (CAMLab)  \n",
    "[2] S. Cuomo *et al*., *Scientific Machine Learning through Physics-Informed Neural Networks: Where we are and What's next*, [arXiv:2201.05624](https://doi.org/10.48550/arXiv.2201.05624)  \n",
    "[3] Aditi S. Krishnapriyan, Amir Gholami, Shandian Zhe, Robert M. Kirby, Michael W. Mahoney, *Characterizing possible failure modes in physics-informed neural networks*, NIPS'21: Proceedings of the 35th International Conference on Neural Information Processing Systems; [arXiv:2109.01050](https://arxiv.org/abs/2109.01050)  \n",
    "[4] D. Mortari, *The Theory of Connections: Connecting Points*, Mathematics, vol. 5, no. 57, 2017.\n",
    "\n",
    "\n",
    "## Local installation `pinn4bhoc`\n",
    "  ```bash\n",
    "      git clone https://github.com/soot-bit/pinn4bhoc\n",
    "      cd pinn4bhoc\n",
    "      pip install -e .\n",
    "  ```\n",
    "## Google Colab installation `pinn4bhoc`\n",
    "  1. Upload `clone2colab.ipynb` from local installation of repo `pinn4bhoc` to working folder on GitHub.\n",
    "  2. Open `clone2colab.ipynb` and set COLAB_FOLDER (default name AIMS) and execute the file.\n",
    "  3. If all is well, open this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8bc211-53b5-4023-8aa9-8cf9820e65f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Google Drive not mounted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    print('\\nGoogle Drive mounted\\n')\n",
    "    %cd /content/gdrive/MyDrive/{COLAB_FOLDER}\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    print('\\nGoogle Drive not mounted\\n')\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    %cd pinn4bhoc\n",
    "    %pip install -e .\n",
    "    print('\\npinn4bhoc installed in Google Drive\\n')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CecIm-CUNcNA",
   "metadata": {
    "id": "CecIm-CUNcNA"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57bd86d0-9a07-4931-91bf-be1c0f702eb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57bd86d0-9a07-4931-91bf-be1c0f702eb6",
    "outputId": "7bf5e1fb-cf25-4e9a-f5ad-feef1d2cbfe8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "# PINN library\n",
    "import pinn4bhoc.nn as mlp\n",
    "import pinn4bhoc.utils.data as dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OboD6tUhK5_r",
   "metadata": {
    "id": "OboD6tUhK5_r"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "730b8300-a871-4851-9faf-143acaf72bfa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "730b8300-a871-4851-9faf-143acaf72bfa",
    "outputId": "1b812450-f2bc-49f0-c380-d757e5caee2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "\n",
      "Save configuration to file runs/2025-10-22_19:25/fcnn_sobol_config.yaml\n",
      "\n",
      "name: fcnn_sobol\n",
      "file:\n",
      "  losses: runs/2025-10-22_19:25/fcnn_sobol_losses.csv\n",
      "  params: runs/2025-10-22_19:25/fcnn_sobol_params.pth\n",
      "  init_params: runs/2025-10-22_19:25/fcnn_sobol_init_params.pth\n",
      "  plots: runs/2025-10-22_19:25/fcnn_sobol_plots.png\n",
      "dPhi: 0.1\n",
      "lower_bounds:\n",
      "- 0.0\n",
      "- 0.1\n",
      "- -1.0\n",
      "upper_bounds:\n",
      "- 0.1\n",
      "- 0.99\n",
      "- 1.0\n",
      "dataset_size_exponent: 16\n",
      "train_size: 65536\n",
      "val_size: 5000\n",
      "batch_size: 2048\n",
      "monitor_step: 2000\n",
      "delete: true\n",
      "num_steps: 5\n",
      "num_iters_per_step: 200000\n",
      "base_lr: 0.003\n",
      "gamma: 0.24\n",
      "val_cost_drop_threshold: 0.005\n",
      "num_iterations: 1000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Hardware\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset Configuration\n",
    "# -----------------------------\n",
    "\"\"\"\n",
    "For tests:\n",
    "n_steps                    = 5        # Number of steps with constant LR\n",
    "n_iterations_per_step      = 2000     # Training iterations per LR step\n",
    "monitor_every_n_iterations = 200      # Frequency of logging/monitoring\n",
    "\"\"\"\n",
    "\n",
    "name = 'fcnn_sobol'\n",
    "\n",
    "# choose whether to create or load a configuration file\n",
    "load_existing_config = False\n",
    "\n",
    "if load_existing_config:\n",
    "    config = mlp.Config(f'{name}.yaml')\n",
    "else:\n",
    "    # create new configuration\n",
    "    config = mlp.Config(name)\n",
    "\n",
    "    # Phi segement size\n",
    "    config('dPhi', 0.1)\n",
    "\n",
    "    # Bounds\n",
    "    #                       Phi     u0    v0\n",
    "    config('lower_bounds', [0.0,  0.10, -1.0])\n",
    "    config('upper_bounds', [config('dPhi'), 0.99,  1.0])\n",
    "\n",
    "    # training configuration\n",
    "    # -----------------------------------------\n",
    "    config('dataset_size_exponent', 16)\n",
    "    config('train_size', 2**config('dataset_size_exponent'))\n",
    "    config('val_size',     5000)  # validation sample size\n",
    "    config('batch_size',   2048)  #\n",
    "    config('monitor_step', 2000)  # monitor training every n (=10) iterations\n",
    "    config('delete', True)        # delete losses file before training, if True\n",
    "\n",
    "    # optimizer / scheduler configuration\n",
    "    # -----------------------------------------\n",
    "    # a step comprises a given number of iterations\n",
    "    config('num_steps', 5)        # number of training steps\n",
    "    config('num_iters_per_step', 200_000)\n",
    "    config('base_lr', 3e-3)       # initial learning rate\n",
    "    config('gamma', 0.24)         # learning rate scale factor\n",
    "    \n",
    "    config('val_cost_drop_threshold', 0.005)\n",
    "    print(f'\\nSave configuration to file {config.cfg_filename}\\n')\n",
    "\n",
    "    config.save()\n",
    "    \n",
    "# Total number of iterations\n",
    "config('num_iterations', config('num_iters_per_step') * config('num_steps'))\n",
    "\n",
    "print(config)\n",
    "\n",
    "# -----------------------------\n",
    "# Live Plotting Options\n",
    "# -----------------------------\n",
    "live_display  = False    # to plot cost evolution during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ewiPspCPRwv",
   "metadata": {
    "id": "8ewiPspCPRwv"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "XibYYt5iPVPY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XibYYt5iPVPY",
    "outputId": "ec7c64bd-ca3e-461d-9f86-d7067ccaed9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SobolSample\n",
      "  65536 Sobol points created.\n",
      "\n",
      "  UniformSample\n",
      "  5000 uniformly sampled points created.\n",
      "\n",
      "===> Creating: train_dataset\n",
      "  Type               : Dataset\n",
      "  Shape of phi_vals  : torch.Size([65536, 1])\n",
      "  Shape of init_conds: torch.Size([65536, 2])\n",
      "\n",
      "===> Creating: train_valsize_dataset\n",
      "  Type               : Dataset\n",
      "  Shape of phi_vals  : torch.Size([5000, 1])\n",
      "  Shape of init_conds: torch.Size([5000, 2])\n",
      "\n",
      "===> Creating: val_dataset\n",
      "  Type               : Dataset\n",
      "  Shape of phi_vals  : torch.Size([5000, 1])\n",
      "  Shape of init_conds: torch.Size([5000, 2])\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Point Generation\n",
    "# -----------------------------\n",
    "# Training data\n",
    "sampling_strategy = 'sobol'\n",
    "\n",
    "if sampling_strategy.lower() == \"sobol\":\n",
    "    data_train = dat.SobolSample(config('lower_bounds'), \n",
    "                                  config('upper_bounds'),\n",
    "                                  num_points_exp=config('dataset_size_exponent')\n",
    "    )\n",
    "elif sampling_strategy.lower() == \"uniform\":\n",
    "    data_train = dat.UniformSample(config('lower_bounds'), \n",
    "                                   config('upper_bounds'),\n",
    "                                   num_points=2**config('dataset_size_exponent')\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"sampling_strategy must be one of: sobol, uniform\")\n",
    "print()\n",
    "\n",
    "# Validation data\n",
    "data_val = dat.UniformSample(config('lower_bounds'), \n",
    "                             config('upper_bounds'),\n",
    "                             num_points=config('val_size')\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# PINN Datasets\n",
    "# -----------------------------\n",
    "# Dataset for training: full tensorized subset from the raw sampling\n",
    "print('\\n===> Creating: train_dataset')\n",
    "train_dataset = dat.Dataset(data_train,\n",
    "                            start=0, end=config('train_size'),\n",
    "                            verbose=1,\n",
    "                            device=device\n",
    ")\n",
    "\n",
    "# Training subset of same size as validation dataset\n",
    "print('\\n===> Creating: train_valsize_dataset')\n",
    "train_valsize_dataset = dat.Dataset(data_train,\n",
    "                                    start=0, end=config('train_size'),\n",
    "                                    random_sample_size=config('val_size'),\n",
    "                                    verbose=1,\n",
    "                                    device=device\n",
    ")\n",
    "\n",
    "# Dataset for validation: tensorized points from the raw uniform sampling\n",
    "print('\\n===> Creating: val_dataset')\n",
    "val_dataset = dat.Dataset(data_val,\n",
    "                          start=0, end=config('val_size'),\n",
    "                          verbose=1,\n",
    "                          device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q12D1HKLToBI",
   "metadata": {
    "id": "Q12D1HKLToBI"
   },
   "source": [
    "# DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "O8nhS9wFV_LB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8nhS9wFV_LB",
    "outputId": "79c9117d-c19e-4473-a076-26c4b134c5d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===> Creating: train_loader\n",
      "DataLoader\n",
      "  Number of iterations has been specified\n",
      "  maxiter:         1000000\n",
      "  batch_size:         2048\n",
      "  shuffle_step:         32\n",
      "\n",
      "\n",
      "===> Creating: val_loader\n",
      "DataLoader\n",
      "  maxiter:               1\n",
      "  batch_size:         5000\n",
      "  shuffle_step:          1\n",
      "\n",
      "\n",
      "===> Creating: train_valsize_loader\n",
      "DataLoader\n",
      "  maxiter:               1\n",
      "  batch_size:         5000\n",
      "  shuffle_step:          1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loader for main training batches\n",
    "print('\\n===> Creating: train_loader')\n",
    "train_loader = dat.DataLoader(train_dataset,\n",
    "                              batch_size=config('batch_size'),\n",
    "                              num_iterations=config('num_iterations'),\n",
    "                              shuffle=True\n",
    ")\n",
    "\n",
    "# Loader for evaluating validation cost (single batch of val_size)\n",
    "print('\\n===> Creating: val_loader')\n",
    "val_loader = dat.DataLoader(val_dataset,\n",
    "                            batch_size=config('val_size')\n",
    ")\n",
    "\n",
    "# Loader for evaluating training cost with val-sized batch\n",
    "print('\\n===> Creating: train_valsize_loader')\n",
    "train_valsize_loader = dat.DataLoader(train_valsize_dataset,\n",
    "                                      batch_size=config('val_size')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ChCe8UIW3_c",
   "metadata": {
    "id": "9ChCe8UIW3_c"
   },
   "source": [
    "## Model, Solution, Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "CTn-yb_DW42a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTn-yb_DW42a",
    "outputId": "e83bac27-4ed0-407d-86c2-772447c3cde5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===> Creating model...\n",
      "\n",
      "FCNN(\n",
      "  (model): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=75, bias=True)\n",
      "    (1): Sin()\n",
      "    (2): Linear(in_features=75, out_features=75, bias=True)\n",
      "    (3): Sin()\n",
      "    (4): Linear(in_features=75, out_features=75, bias=True)\n",
      "    (5): Sin()\n",
      "  )\n",
      "  (output_layer): Linear(in_features=75, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters: 11776\n",
      "\n",
      "===> Saved initial model weights to:\n",
      "\truns/2025-10-22_19:25/fcnn_sobol_init_params.pth\n"
     ]
    }
   ],
   "source": [
    "# Model Instantiation\n",
    "print('\\n===> Creating model...\\n')\n",
    "\n",
    "fcnn_model = mlp.FCNN().to(device)\n",
    "pinn_soln  = mlp.Solution(fcnn_model).to(device)\n",
    "pinn_obj   = mlp.Objective(pinn_soln).to(device)\n",
    "\n",
    "print(fcnn_model)\n",
    "print(f'Number of parameters: {mlp.count_trainable_parameters(fcnn_model)}')\n",
    "\n",
    "# Save model with initial weights\n",
    "init_model_filename = config('file/init_params')\n",
    "fcnn_model.save(init_model_filename)\n",
    "\n",
    "print(f\"\\n===> Saved initial model weights to:\\n\\t{init_model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92qpdDruZBBa",
   "metadata": {
    "id": "92qpdDruZBBa"
   },
   "source": [
    "# Scheduler\n",
    "Using a multistep scheduler parametrized with $\\gamma$ (initially 0.24).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "uHJxWZ3JZDNn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHJxWZ3JZDNn",
    "outputId": "6217eca2-a951-4d1a-b24b-151c50deda97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===> Creating optimizer...\n",
      "\n",
      "    Base learning rate:    3.0e-03\n",
      "    Number of milestones:     4\n",
      "\n",
      "\n",
      "===> Creating scheduler...\n",
      "\n",
      "Step | Milestone | LR\n",
      "-----------------------------\n",
      "   0 |         0 | 3.0e-03   \n",
      "-----------------------------\n",
      "   1 |    200000 | 7.2e-04   \n",
      "   2 |    400000 | 1.7e-04   \n",
      "   3 |    600000 | 4.1e-05   \n",
      "   4 |    800000 | 1.0e-05   \n",
      "\n",
      "Total number of iterations:    1000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate optimizer with base learning rate\n",
    "print(\"\\n===> Creating optimizer...\\n\")\n",
    "print(f\"    Base learning rate: {config('base_lr'):10.1e}\")\n",
    "optimizer = torch.optim.Adam(pinn_soln.parameters(), lr=config('base_lr'))\n",
    "\n",
    "# Learning rate milestones (after n_step iterations)\n",
    "n_milestones = config('num_steps') - 1\n",
    "print(f'    Number of milestones: {n_milestones:5d}\\n')\n",
    "milestones = [n * config('num_iters_per_step') for n in range(config('num_steps'))]\n",
    "\n",
    "print(\"\\n===> Creating scheduler...\\n\")\n",
    "# Drop first entry of milestones list because it contains the base LR\n",
    "scheduler = MultiStepLR(optimizer, milestones=milestones[1:], gamma=config('gamma'))\n",
    "\n",
    "mlp.print_milestones_and_lrs(config('base_lr'), \n",
    "                             config('num_steps'), \n",
    "                             milestones,\n",
    "                             config('gamma'),\n",
    "                             n_max_iterations=config('num_iterations'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LRk5UjmIgIfN",
   "metadata": {
    "id": "LRk5UjmIgIfN"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "WuuGvgso_dR1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "WuuGvgso_dR1",
    "outputId": "af289376-db83-4c18-f466-24e54ee41bb6"
   },
   "outputs": [],
   "source": [
    "mlp.train_pinn(train_loader, val_loader, train_valsize_loader,\n",
    "               optimizer, scheduler, pinn_obj,\n",
    "               display_costs=live_display,\n",
    "               model_filename=config('file/params'),\n",
    "               log_filename=config('file/losses'),\n",
    "               plot_filename=config('file/plots'),\n",
    "               monitor_every_n_iterations=config('monitor_step'),\n",
    "               drop_threshold=config('val_cost_drop_threshold')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644749ca-7e18-414a-bacf-1c0e82e3eacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
